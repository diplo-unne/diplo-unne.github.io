{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c0be799351746fdb0f7e46da5645bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f57fafdba18b4d01980259790ea73d01",
              "IPY_MODEL_31ff7d9d40e54d4d96b3d77ab1869465",
              "IPY_MODEL_d83d0cf15f0d40778c4fecc7a6675a81"
            ],
            "layout": "IPY_MODEL_b73bc13ee6e643d3b36b5eb732484ffc"
          }
        },
        "f57fafdba18b4d01980259790ea73d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f82e218951604f0eb9d08e288807235a",
            "placeholder": "​",
            "style": "IPY_MODEL_f8416763206a48da9a20c1e7d43c3172",
            "value": "Map: 100%"
          }
        },
        "31ff7d9d40e54d4d96b3d77ab1869465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41efe29595124beba0f320e84bdf3fd2",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd5023e33063407bb7423ed37db9c4cf",
            "value": 200
          }
        },
        "d83d0cf15f0d40778c4fecc7a6675a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7574cdd7f6784e7ca95f7f2292b73bc6",
            "placeholder": "​",
            "style": "IPY_MODEL_c266c855c4c74b2db4806737d96ef102",
            "value": " 200/200 [00:00&lt;00:00, 1522.69 examples/s]"
          }
        },
        "b73bc13ee6e643d3b36b5eb732484ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82e218951604f0eb9d08e288807235a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8416763206a48da9a20c1e7d43c3172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41efe29595124beba0f320e84bdf3fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd5023e33063407bb7423ed37db9c4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7574cdd7f6784e7ca95f7f2292b73bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c266c855c4c74b2db4806737d96ef102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clase 6\n",
        "\n",
        "### BERT y Análisis de Sentimientos\n",
        "\n",
        "En este cuaderno, exploramos el uso de **BERT** (*Bidirectional Encoder Representations from Transformers*), un modelo de lenguaje basado en *transformers* desarrollado por Google. BERT es ampliamente utilizado en tareas de procesamiento de lenguaje natural (NLP), como clasificación de textos, respuestas a preguntas y análisis de sentimientos, gracias a su capacidad para comprender el contexto bidireccional de las palabras en una oración.\n",
        "\n",
        "###  ¿Qué es BERT?\n",
        "BERT es un modelo preentrenado que entiende el lenguaje humano a partir de grandes corpus de texto. A diferencia de los enfoques tradicionales, BERT analiza las palabras teniendo en cuenta tanto el contexto previo como el posterior en una oración, lo que mejora significativamente su capacidad para interpretar el significado.\n",
        "\n",
        "###  ¿Qué hacemos en este cuaderno?\n",
        "- Cargamos un modelo BERT preentrenado para la tarea de **análisis de sentimientos**.\n",
        "- Preprocesamos un conjunto de datos que contiene textos y etiquetas de sentimiento (positivo, neutro, negativo).\n",
        "- Entrenamos el modelo utilizando un dataset en español y evaluamos su rendimiento.\n",
        "- Realizamos predicciones sobre nuevos textos para determinar su sentimiento.\n",
        "- Finalmente, analizamos un archivo con comentarios para clasificar automáticamente sus sentimientos.\n",
        "\n"
      ],
      "metadata": {
        "id": "itHOMCMXAiZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbpEC1tf04oh",
        "outputId": "86ab7b6d-b00c-4b54-d086-dc573f5b4d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m546.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, transformers, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.2\n",
            "    Uninstalling transformers-4.46.2:\n",
            "      Successfully uninstalled transformers-4.46.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 transformers-4.46.3 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Instalar/Reinstalar las bibliotecas necesarias\n",
        "!pip install transformers datasets accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "print(\"Descargando dataset...\")\n",
        "url = 'https://drive.google.com/uc?export=download&id=1IRI3NN3wDB3ZPKj7mMNCQTkqF7OYdP5W'\n",
        "destination = \"tweet_eval_sentiment_es.zip\"\n",
        "gdown.download(url, destination, quiet=False)\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('tweet_eval_sentiment_es.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('')  # Cambia 'ruta_de_extraccion' si quieres un nombre específ\n",
        "\n",
        "# URL del archivo de texto con comentarios de clientes\n",
        "url_comentarios = 'https://drive.google.com/uc?export=download&id=12c_JKSe7ijkoMAOpSeJuVWjzfDyh1JIn'\n",
        "destination = \"comentarios.txt\"\n",
        "gdown.download(url_comentarios, destination, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "sNQTsJJ6093y",
        "outputId": "e249f66b-a06c-4a1c-9fc8-c34f48ab9d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1IRI3NN3wDB3ZPKj7mMNCQTkqF7OYdP5W\n",
            "To: /content/tweet_eval_sentiment_es.zip\n",
            "100%|██████████| 57.4k/57.4k [00:00<00:00, 3.84MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=12c_JKSe7ijkoMAOpSeJuVWjzfDyh1JIn\n",
            "To: /content/comentarios.txt\n",
            "100%|██████████| 1.99k/1.99k [00:00<00:00, 1.59MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'comentarios.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 1"
      ],
      "metadata": {
        "id": "EQPhcmBZ_rPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Importar las bibliotecas necesarias\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_from_disk, Dataset\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Deshabilitar wandb\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Cargar el dataset traducido desde la carpeta\n",
        "translated_dataset = Dataset.load_from_disk('tweet_eval_sentiment_es')\n",
        "\n",
        "# Verificar y mostrar los primeros 5 elementos\n",
        "for idx, item in enumerate(translated_dataset.select(range(5))):\n",
        "    print(f\"Ejemplo {idx + 1}:\")\n",
        "    print(f\"Texto: {item['text']}\")\n",
        "    print(f\"Etiqueta: {item['label']}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Mostrar la distribución de etiquetas en el dataset completo\n",
        "label_counts = Counter(translated_dataset['label'])\n",
        "print(\"\\nDistribución de etiquetas en el dataset:\")\n",
        "print(label_counts)\n",
        "\n",
        "# Paso 2: Preprocesar los datos\n",
        "# Cargar el tokenizador del modelo multilingüe\n",
        "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "# Función para tokenizar los textos\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Dividir y tokenizar el dataset\n",
        "train_dataset = translated_dataset.shuffle(seed=42).select(range(800)).map(tokenize_function, batched=True)\n",
        "test_dataset = translated_dataset.shuffle(seed=42).select(range(800, 1000)).map(tokenize_function, batched=True)\n",
        "\n",
        "# Establecer el formato de los datos para PyTorch\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Paso 3: Configurar el modelo y el entrenamiento\n",
        "\n",
        "# Usar la GPU si está disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Cargar el modelo multilingüe pre-entrenado con ignore_mismatched_sizes=True\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'nlptown/bert-base-multilingual-uncased-sentiment',\n",
        "    num_labels=3,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(device)\n",
        "\n",
        "# Configurar los argumentos del entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Crear el trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Paso 4: Entrenar el modelo\n",
        "trainer.train()\n",
        "\n",
        "# Paso 5: Evaluar el modelo\n",
        "trainer.evaluate()\n",
        "\n",
        "# Paso 6: Definir el Mapeo de Etiquetas\n",
        "label_map = {0: \"negativo\", 1: \"neutro\", 2: \"positivo\"}\n",
        "\n",
        "# Paso 7: Hacer Inferencias\n",
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_id = logits.argmax().item()\n",
        "    return label_map[predicted_class_id]\n",
        "\n",
        "# Ejemplo de uso\n",
        "print(predict_sentiment(\"Este producto es genial!\"))\n",
        "print(predict_sentiment(\"Este producto es terrible.\"))\n",
        "\n",
        "# Leer y analizar los comentarios\n",
        "with open('comentarios.txt', 'r') as file:\n",
        "    comentarios = file.readlines()\n",
        "\n",
        "comentarios_sentimientos = [(comentario.strip(), predict_sentiment(comentario.strip())) for comentario in comentarios]\n",
        "\n",
        "# Crear un DataFrame con los resultados\n",
        "df_sentimientos = pd.DataFrame(comentarios_sentimientos, columns=['Comentario', 'Sentimiento'])\n",
        "print(df_sentimientos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2c0be799351746fdb0f7e46da5645bc0",
            "f57fafdba18b4d01980259790ea73d01",
            "31ff7d9d40e54d4d96b3d77ab1869465",
            "d83d0cf15f0d40778c4fecc7a6675a81",
            "b73bc13ee6e643d3b36b5eb732484ffc",
            "f82e218951604f0eb9d08e288807235a",
            "f8416763206a48da9a20c1e7d43c3172",
            "41efe29595124beba0f320e84bdf3fd2",
            "cd5023e33063407bb7423ed37db9c4cf",
            "7574cdd7f6784e7ca95f7f2292b73bc6",
            "c266c855c4c74b2db4806737d96ef102"
          ]
        },
        "id": "QpvP937i5wMd",
        "outputId": "83eb1da8-641a-410c-b6d8-fa01adaf90c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo 1:\n",
            "Texto: \"QT @user En el borrador original del séptimo libro, Remus Lupin sobrevivió a la batalla de Hogwarts. #HappyBirthdayRemusLupin\"\n",
            "Etiqueta: 2\n",
            "----------------------------------------\n",
            "Ejemplo 2:\n",
            "Texto: \"Ben Smith / Smith (concusión) permanece fuera de la alineación el jueves, Curtis #NHL #SJ\"\n",
            "Etiqueta: 1\n",
            "----------------------------------------\n",
            "Ejemplo 3:\n",
            "Texto: Lo siento por el arroyo anoche me estrellé pero estaré esta noche seguro, y luego de vuelta a Minecraft en el PC mañana por la noche.\n",
            "Etiqueta: 1\n",
            "----------------------------------------\n",
            "Ejemplo 4:\n",
            "Texto: El doble RBI de Chase Headley en la octava entrada de David Price rompió una racha de Yankees de 33 entradas consecutivas sin anotación contra Blue Jays\n",
            "Etiqueta: 1\n",
            "----------------------------------------\n",
            "Ejemplo 5:\n",
            "Texto: @user Alciato: Bee invertirá 150 millones en enero, otros 200 en el verano y planea traer a Messi para 2017\"\n",
            "Etiqueta: 2\n",
            "----------------------------------------\n",
            "\n",
            "Distribución de etiquetas en el dataset:\n",
            "Counter({1: 460, 2: 389, 0: 151})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c0be799351746fdb0f7e46da5645bc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 04:58, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.099400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.034200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.027900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.981100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.934600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.834400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.838500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.805200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.712700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.725500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.683200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.801300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.748200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.515300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.538100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.477700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.458100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.484400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positivo\n",
            "negativo\n",
            "                                           Comentario Sentimiento\n",
            "0   La entrega fue puntual, pero el embalaje podrí...      neutro\n",
            "1   La atención al cliente fue buena, pero el prod...    negativo\n",
            "2   El servicio fue adecuado, pero podría mejorar ...      neutro\n",
            "3   El producto es bueno, aunque esperaba algo más...    positivo\n",
            "4               Calidad media, pero no me impresionó.      neutro\n",
            "5   El servicio fue rápido, pero no resolvieron to...      neutro\n",
            "6   El producto es funcional, pero esperaba algo m...      neutro\n",
            "7   La entrega fue puntual, pero el embalaje estab...      neutro\n",
            "8   La calidad es media, cumple con lo básico pero...      neutro\n",
            "9   El producto es funcional, pero no cumple todas...      neutro\n",
            "10  El diseño es atractivo, pero no es muy cómodo ...      neutro\n",
            "11  El precio es razonable, pero la calidad no es ...      neutro\n",
            "12  El servicio al cliente fue rápido, pero no res...    negativo\n",
            "13                 El producto cumple con su función.    positivo\n",
            "14  El servicio al cliente fue adecuado, pero no e...      neutro\n",
            "15  La atención fue rápida, aunque no resolvieron ...      neutro\n",
            "16  Está bien, cumple su función, pero no me impre...      neutro\n",
            "17                    No es bueno, pero tampoco malo.    negativo\n",
            "18  El diseño es atractivo, pero el funcionamiento...      neutro\n",
            "19  El producto es funcional, pero no cumple todas...      neutro\n",
            "20  El producto es bueno, aunque es muy alto el pr...      neutro\n",
            "21  El diseño es atractivo, pero la funcionalidad ...      neutro\n",
            "22    El precio es justo, aunque esperaba algo mejor.      neutro\n",
            "23  El producto cumple con su función, aunque no e...      neutro\n",
            "24      El producto está bien, pero no me impresionó.      neutro\n",
            "25  El producto cumple su función, aunque no super...      neutro\n",
            "26  El producto es aceptable, aunque esperaba más ...      neutro\n",
            "27  Cumple con lo básico, pero no tiene caracterís...      neutro\n",
            "28  La calidad es aceptable, aunque podría ser mejor.      neutro\n",
            "29                  He visto mejores por este precio.      neutro\n",
            "30  El producto es decente, aunque no es el mejor ...      neutro\n",
            "31   El producto llegó dañado, necesito un reemplazo.    negativo\n",
            "32  La calidad es aceptable, pero he visto mejores...      neutro\n",
            "33  Cumple con lo básico, pero no destaca en ningú...      neutro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agregar datos al dataset tweet_eval_sentiment_es"
      ],
      "metadata": {
        "id": "TAQ8oXfY_nLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Importar las bibliotecas necesarias\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_from_disk, Dataset, concatenate_datasets, Features, Value\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import requests\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Deshabilitar wandb\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Paso 2: Cargar el dataset traducido desde la carpeta\n",
        "translated_dataset = load_from_disk('tweet_eval_sentiment_es')\n",
        "\n",
        "\n",
        "# Mostrar la distribución de etiquetas en el dataset completo\n",
        "label_counts = Counter(translated_dataset['label'])\n",
        "print(\"\\nDistribución de etiquetas en el dataset:\")\n",
        "print(label_counts)\n",
        "\n",
        "# Paso 3: Crear la lista de ejemplos negativos adicionales\n",
        "extra_negatives = [\n",
        "    {\"text\": \"No volvería a comprar, mala experiencia.\", \"label\": 0},\n",
        "    {\"text\": \"El producto llegó dañado, no recomiendo.\", \"label\": 0},\n",
        "    {\"text\": \"Muy mala calidad, no cumplió mis expectativas.\", \"label\": 0},\n",
        "    {\"text\": \"El color no coincide con la descripción, decepcionante.\", \"label\": 0},\n",
        "    {\"text\": \"Servicio al cliente deficiente, no solucionaron mi problema.\", \"label\": 0}\n",
        "]\n",
        "\n",
        "# Obtener el esquema de características del dataset original\n",
        "label_feature = translated_dataset.features['label']\n",
        "\n",
        "# Definir las características para el nuevo dataset\n",
        "features = Features({\n",
        "    'text': Value('string'),\n",
        "    'label': label_feature\n",
        "})\n",
        "\n",
        "# Crear el dataset adicional con las características especificadas\n",
        "extra_negatives_dataset = Dataset.from_list(extra_negatives, features=features)\n",
        "\n",
        "# Combinar el dataset traducido con los ejemplos negativos adicionales\n",
        "augmented_dataset = concatenate_datasets([translated_dataset, extra_negatives_dataset])\n",
        "\n",
        "# Mostrar la distribución de etiquetas en el dataset aumentado\n",
        "label_counts_augmented = Counter(augmented_dataset['label'])\n",
        "print(\"\\nDistribución de etiquetas en el dataset aumentado:\")\n",
        "print(label_counts_augmented,\"\\n\")\n",
        "print(\"-\"*100)\n",
        "dataset_size = len(augmented_dataset)\n",
        "\n",
        "# Verificar y mostrar los primeros 5 elementos\n",
        "for idx, item in enumerate(augmented_dataset.select(range(5))):\n",
        "    print(f\"Ejemplo {idx + 1}:\")\n",
        "    print(f\"Texto: {item['text']}\")\n",
        "    print(f\"Etiqueta: {item['label']}\")\n",
        "    print(\"-\" * 40)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZX83Nt673lT",
        "outputId": "e66ac1ff-8f26-4cd0-e051-aea93461cd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribución de etiquetas en el dataset:\n",
            "Counter({1: 460, 2: 389, 0: 151})\n",
            "\n",
            "Distribución de etiquetas en el dataset aumentado:\n",
            "Counter({1: 460, 2: 389, 0: 156}) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ejemplo 1:\n",
            "Texto: \"QT @user En el borrador original del séptimo libro, Remus Lupin sobrevivió a la batalla de Hogwarts. #HappyBirthdayRemusLupin\"\n",
            "Etiqueta: 2\n",
            "----------------------------------------\n",
            "Ejemplo 2:\n",
            "Texto: \"Ben Smith / Smith (concusión) permanece fuera de la alineación el jueves, Curtis #NHL #SJ\"\n",
            "Etiqueta: 1\n",
            "----------------------------------------\n",
            "Ejemplo 3:\n",
            "Texto: Lo siento por el arroyo anoche me estrellé pero estaré esta noche seguro, y luego de vuelta a Minecraft en el PC mañana por la noche.\n",
            "Etiqueta: 1\n",
            "----------------------------------------\n",
            "Ejemplo 4:\n",
            "Texto: El doble RBI de Chase Headley en la octava entrada de David Price rompió una racha de Yankees de 33 entradas consecutivas sin anotación contra Blue Jays\n",
            "Etiqueta: 1\n",
            "----------------------------------------\n",
            "Ejemplo 5:\n",
            "Texto: @user Alciato: Bee invertirá 150 millones en enero, otros 200 en el verano y planea traer a Messi para 2017\"\n",
            "Etiqueta: 2\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO 1: Añadir más ejemplos negativos, positivos y neutros para equilibrar aún más el dataset.\n",
        "\n",
        "# TODO 2: Combinar el dataset con los ejemplos adicionales\n",
        "\n",
        "# TODO 3: Entrenar con el dataset aumentado\n",
        "\n",
        "# TODO 4: Evaluar el modelo usando una métrica adicional, como f1-score, ROC-AUC, o la que considere adecuada.\n",
        "\n",
        "# TODO 5: Modificar hiperparámetros como lr, batch_size, num_epochs y otros que considere necesario, para optimizar el modelo.\n",
        "\n",
        "# TODO 6: Implementar early stopping para evitar sobreajuste.\n"
      ],
      "metadata": {
        "id": "RS8E2L7w6GqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# complementario\n",
        "# Probar con un modelo pre-entrenado diferente, por ejemplo, 'dccuchile/bert-base-spanish-wwm-cased'."
      ],
      "metadata": {
        "id": "4F2tNODS7E-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}